{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8804509-85cd-42d6-b654-3e50dc662e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c8893f-d713-485c-8fe4-43883a0c4dfb",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   home_ownership    income    dti  fico  loan_status\n",
      "0               1   44304.0  18.47   690            0\n",
      "1               0   50000.0  29.62   735            1\n",
      "2               0   64400.0  16.68   675            1\n",
      "3               0   38500.0  33.73   660            0\n",
      "4               1  118000.0  26.66   665            1\n",
      "-------------------------------------------\n",
      "   home_ownership    income    dti  fico  loan_status\n",
      "0               0   25000.0  27.60   660            0\n",
      "1               0   50000.0  21.51   715            1\n",
      "2               1  100000.0   8.14   770            1\n",
      "3               0   75000.0   1.76   685            0\n",
      "4               1   78000.0  16.11   680            1\n",
      "-------------------------------------------\n",
      "   home_ownership    income    dti  fico  loan_status\n",
      "0               1   52400.0  24.64   665            1\n",
      "1               1  150000.0  17.04   785            1\n",
      "2               1  100000.0  20.92   710            1\n",
      "3               0   97000.0  13.11   705            1\n",
      "4               1  100000.0  24.08   685            0\n"
     ]
    }
   ],
   "source": [
    "# read data and print it to see what we're working with\n",
    "train = pd.read_excel(\"lendingclub_traindata.xlsx\")\n",
    "print(train.head())\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "validation = pd.read_excel(\"lendingclub_valdata.xlsx\")\n",
    "validation.rename(columns={'homw_ownership':'home_ownership'},inplace=True)\n",
    "print(validation.head())\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "test = pd.read_excel(\"lendingclub_testdata.xlsx\")\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440da698-17f3-45d1-b2e1-7b1fc3913a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the loan status column to create a feature only dataset\n",
    "x_train = train.drop('loan_status',axis=1)\n",
    "x_val = validation.drop('loan_status',axis=1)\n",
    "x_test = test.drop('loan_status',axis=1)\n",
    "\n",
    "# Create scaled feature only datasets \n",
    "x_testScale = (x_test-x_train.mean())/x_train.std()\n",
    "x_valScale = (x_val-x_train.mean())/x_train.std()\n",
    "x_trainScale = (x_train-x_train.mean())/x_train.std()\n",
    "\n",
    "# store target column as y-variables\n",
    "y_train = train['loan_status']\n",
    "y_val = validation['loan_status']\n",
    "y_test = test['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0900d6-a945-4fc1-a3b3-c4e098426aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.03898462] [[ 2.97143081e-01  6.19442465e-07 -3.65107852e-02  1.13438308e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of logisitic regression and fit the logistic regression to the dataset \n",
    "lgstc_reg = LogisticRegression(penalty=None,solver=\"newton-cg\")\n",
    "lgstc_reg.fit(x_train, y_train)\n",
    "\n",
    "# Print the intercept and coefficients for each feature\n",
    "print(lgstc_reg.intercept_, lgstc_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc0c48d-975a-4d06-a463-9731c8e742a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.41622043] [[ 0.14529381  0.03361951 -0.32404237  0.363174  ]]\n"
     ]
    }
   ],
   "source": [
    "# As above but for the scaled datasets\n",
    "lgstc_regScale = LogisticRegression(penalty=None,solver=\"newton-cg\")\n",
    "lgstc_regScale.fit(x_trainScale, y_train)\n",
    "print(lgstc_regScale.intercept_, lgstc_regScale.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1887013-3714-476b-b274-2060c95f672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost function training set = 0.4911114356066864\n",
      "Cost function validation set = 0.48607087962794676\n",
      "Cost function test set = 0.4846698447947508\n"
     ]
    }
   ],
   "source": [
    "# get the predicted probabilities for the dataset\n",
    "y_trainScale_pred = lgstc_regScale.predict_proba(x_trainScale)\n",
    "y_valScale_pred = lgstc_regScale.predict_proba(x_valScale)\n",
    "y_testScale_pred = lgstc_regScale.predict_proba(x_testScale)\n",
    "\n",
    "# Calculate the maximum likelihood for the training, validation and test set\n",
    "mle_vector_trainScale = np.log(np.where(y_train == 1,\n",
    "                                        y_trainScale_pred[:,1],\n",
    "                                        y_trainScale_pred[:,0]))\n",
    "mle_vector_valScale = np.log(np.where(y_val == 1,\n",
    "                                      y_valScale_pred[:,1],\n",
    "                                      y_valScale_pred[:,0]))\n",
    "mle_vector_testScale = np.log(np.where(y_test == 1,\n",
    "                                       y_testScale_pred[:,1],\n",
    "                                       y_testScale_pred[:,0]))\n",
    "\n",
    "# Calculate the cost functions fromthe macimum likelihood and print them out\n",
    "cost_function_trainScale = np.negative(np.sum(mle_vector_trainScale)/len(y_train))\n",
    "cost_function_valScale = np.negative(np.sum(mle_vector_valScale)/len(y_val))\n",
    "cost_function_testScale = np.negative(np.sum(mle_vector_testScale)/len(y_test))\n",
    "\n",
    "print(f\"Cost function training set = {cost_function_trainScale}\") \n",
    "print(f\"Cost function validation set = {cost_function_valScale}\")\n",
    "print(f\"Cost function test set = {cost_function_testScale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a988abd-65a8-49bd-8060-c4456b1cd2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for threshold = 0.75\n",
      "[[60.82969432 18.34061135]\n",
      " [11.70305677  9.12663755]]\n",
      "  \n",
      "Confusion matrix for threshold = 0.8\n",
      "[[42.70742358 36.4628821 ]\n",
      " [ 6.4628821  14.36681223]]\n",
      "  \n",
      "Confusion matrix for threshold = 0.85\n",
      "[[22.7510917  56.41921397]\n",
      " [ 3.01310044 17.81659389]]\n",
      "  \n",
      "All Metrics\n",
      "                            0         1         2\n",
      "Threshold                0.75       0.8      0.85\n",
      "Accuracy             0.699563  0.570742  0.405677\n",
      "True Positive Rate    0.76834  0.539437  0.287369\n",
      "True Negative Rate   0.438155  0.689727  0.855346\n",
      "False Positive Rate  0.561845  0.310273  0.144654\n",
      "Precision            0.838651  0.868561  0.883051\n",
      "F-score              0.801957  0.665532  0.433625\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = [0.75, 0.80, 0.85]\n",
    "\n",
    "# Create a dataframe to store the results\n",
    "results = pd.DataFrame(columns=[\"Threshold\",\"Accuracy\",\"True Positive Rate\",\"True Negative Rate\",\n",
    "                                \"False Positive Rate\",\"Precision\",\"F-score\"])\n",
    "\n",
    "results[\"Threshold\"] = THRESHOLD\n",
    "\n",
    "j=0\n",
    "\n",
    "for i in THRESHOLD:\n",
    "    lgstc_regScale.fit(x_trainScale, y_train)\n",
    "    \n",
    "    # if probability for test set > threshold predction\n",
    "    preds = np.where(lgstc_regScale.predict_proba(x_testScale)[:,1]>i,1,0)\n",
    "\n",
    "    # create confusion matrix\n",
    "    cm = (confusion_matrix(y_test,preds,labels=[1, 0],sample_weight=None) / len(y_test))*100\n",
    "    print(f\"Confusion matrix for threshold = {i}\")\n",
    "    print(cm)\n",
    "    print(\"  \")\n",
    "\n",
    "    TP = cm[0][0]\n",
    "    FN = cm[0][1]\n",
    "    FP = cm[1][0]\n",
    "    TN = cm[1][1]\n",
    "\n",
    "    results.iloc[j,1] = accuracy_score(y_test,preds)\n",
    "    results.iloc[j,2] = recall_score(y_test,preds)\n",
    "    results.iloc[j,3] = TN/(FP+TN)\n",
    "    results.iloc[j,4] = FP/(FP+TN)\n",
    "    results.iloc[j,5] = precision_score(y_test,preds)\n",
    "    results.iloc[j,6] = f1_score(y_test,preds)\n",
    "\n",
    "    j += 1\n",
    "\n",
    "print(\"All Metrics\")\n",
    "print(results.T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e78787-e305-4bba-98e1-2749b95b1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the receiver operating curve and the AUC measure\n",
    "lr_prob=lgstc_regScale.predict_proba(x_testScale)\n",
    "lr_prob=lr_prob[:,1]\n",
    "\n",
    "ns_prob=[0 for _ in range(len(y_test))]\n",
    "ns_auc=roc_auc_score(y_test,ns_prob)\n",
    "lr_auc=roc_auc_score(y_test,lr_prob)\n",
    "\n",
    "print(f\"AUC Random Predictions = {ns_auc}\")\n",
    "print(f\"AUC predictions from logistic regression model = {lr_auc}\")\n",
    "\n",
    "ns_fpr,ns_tpr,_=roc_curve(y_test,ns_prob)\n",
    "lr_fpr,lr_tpr,_=roc_curve(y_test,lr_prob)\n",
    "\n",
    "plt.plot(ns_fpr,ns_tpr,linestyle=\"--\",label=\"Random Prediction\")\n",
    "plt.plot(lr_fpr,lr_tpr,marker=\".\",label=\"Logisitic Regression\")\n",
    "\n",
    "plt.xlabel(\"False positive rate\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
